{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2de04a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from feature_engine import imputation as mdi\n",
    "from feature_engine import encoding as ce\n",
    "import mean_median2 as mm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def get_path():\n",
    "    cur_path = os.getcwd()\n",
    "    parent_path = os.path.dirname(cur_path)\n",
    "    return cur_path, parent_path\n",
    "\n",
    "\n",
    "def file_path(data_path, file):\n",
    "    return os.path.abspath(os.path.join(data_path, f'{file}'))\n",
    "\n",
    "\n",
    "def df_write(data_path, df, file):\n",
    "    df = df.copy()\n",
    "    df.to_csv(os.path.abspath(os.path.join(data_path, file)), index=False)\n",
    "\n",
    "\n",
    "def split_train_test(df, configs):\n",
    "    df = df.copy()\n",
    "    X = df.drop(columns=configs['y_col'][0])\n",
    "    y = df[configs['y_col'][0]]\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=configs['y_col'][0])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n",
    "    print(39, len(X_train))\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def model_selection(option='logic'):\n",
    "    if option == 'light':\n",
    "        return lgb.LGBMClassifier(random_state=0)\n",
    "    else:\n",
    "        return LogisticRegression(random_state=0)\n",
    "\n",
    "\n",
    "def read_data(configs):\n",
    "    if configs['date_col'][0] == ' ':\n",
    "        df = pd.read_csv(configs['file_name'][0])\n",
    "    else:\n",
    "        df = pd.read_csv(configs['file_name'][0], parse_dates=configs['date_col'])\n",
    "\n",
    "    if configs['remove_col'][0] == ' ':\n",
    "        pass\n",
    "    else:\n",
    "#         configs['remove_col'][0].split(',')\n",
    "        if configs['remove_col'][0] in df.columns.to_list():\n",
    "            df = df.drop(configs['remove_col'][0], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def y_label_enc(df, configs):\n",
    "    df = df.copy()\n",
    "    Y_col = configs['y_col'][0]\n",
    "    if df[Y_col].isnull().any():\n",
    "        Y_null = True\n",
    "    else:\n",
    "        Y_null = False\n",
    "    labeler = LabelEncoder()\n",
    "    df[Y_col] = labeler.fit_transform(df[Y_col])\n",
    "    return df, Y_null\n",
    "\n",
    "    \n",
    "def organize_data(df, configs, y_null):\n",
    "    df = df.copy()\n",
    "    cols = df.columns.to_list()\n",
    "    null_threshhold_cols = []\n",
    "    no_null_cols = []\n",
    "    date_time = configs['date_col']\n",
    "    Y_col = configs['y_col'][0]\n",
    "\n",
    "    for col in cols:\n",
    "        null_mean = df[col].isnull().mean()\n",
    "        if null_mean >= configs['null_threshhold'][0]:\n",
    "            null_threshhold_cols.append(col)\n",
    "        if null_mean == 0:\n",
    "            no_null_cols.append(col)\n",
    "\n",
    "    cols_stayed = [item for item in cols if item not in null_threshhold_cols]\n",
    "    data = df[cols_stayed].copy()\n",
    "\n",
    "    # numerical: discrete vs continuous\n",
    "    discrete = [var for var in cols_stayed if\n",
    "                data[var].dtype != 'O' and var != Y_col and var not in date_time and data[var].nunique() < 10]\n",
    "    continuous = [var for var in cols_stayed if\n",
    "                  data[var].dtype != 'O' and var != Y_col and var not in date_time and var not in discrete]\n",
    "\n",
    "    # categorical\n",
    "    categorical = [var for var in cols_stayed if data[var].dtype == 'O' and var != Y_col]\n",
    "\n",
    "    print('There are {} date_time variables'.format(len(date_time)))\n",
    "    print('There are {} discrete variables'.format(len(discrete)))\n",
    "    print('There are {} continuous variables'.format(len(continuous)))\n",
    "    print('There are {} categorical variables'.format(len(categorical)))\n",
    "\n",
    "    if y_null:\n",
    "        data = data[data[Y_col] != data[Y_col].max()].copy()\n",
    "    else:\n",
    "        data = data.copy()\n",
    "\n",
    "    return data, discrete, continuous, categorical\n",
    "\n",
    "\n",
    "def make_train_test(df, configs):\n",
    "    df = df.copy()\n",
    "    X = df.drop(columns=configs['y_col'][0])\n",
    "    y = df[configs['y_col'][0]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=configs['test_size'][0], random_state=0, stratify=y)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def make_imputer_pipe(continuous, discrete, categorical, null_impute_type=None):\n",
    "    numberImputer = continuous + discrete\n",
    "    categoricalImputer = categorical\n",
    "    \n",
    "    if null_impute_type is None:\n",
    "        pipe = []\n",
    "    else:\n",
    "        if (len(numberImputer) > 0) & (len(categoricalImputer) > 0):\n",
    "            pipe = Pipeline([\n",
    "                (\"imputer\",\n",
    "                 mm.MeanMedianImputer2(\n",
    "                     imputation_method=null_impute_type, variables=numberImputer),),\n",
    "    \n",
    "                ('imputer_cat',\n",
    "                 mdi.CategoricalImputer(variables=categoricalImputer)),\n",
    "    \n",
    "                ('categorical_encoder',\n",
    "                 ce.OrdinalEncoder(encoding_method='ordered',\n",
    "                                   variables=categoricalImputer))\n",
    "            ])\n",
    "        else:\n",
    "            if (len(numberImputer) > 0) & (len(categoricalImputer) == 0):\n",
    "                pipe = Pipeline([\n",
    "                    (\"imputer\",\n",
    "                     mm.MeanMedianImputer2(\n",
    "                         imputation_method=null_impute_type, variables=numberImputer),)\n",
    "                ])\n",
    "            else:\n",
    "                if (len(numberImputer) == 0) & (len(categoricalImputer) > 0):\n",
    "                    pipe = Pipeline([\n",
    "                        ('imputer_cat',\n",
    "                         mdi.CategoricalImputer(variables=categoricalImputer)),\n",
    "    \n",
    "                        ('categorical_encoder',\n",
    "                         ce.OrdinalEncoder(encoding_method='ordered',\n",
    "                                           variables=categoricalImputer))\n",
    "                    ])\n",
    "                else:\n",
    "                    pipe = []\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def do_imputation(df, configs, pipe):\n",
    "    if pipe != []:\n",
    "        df = df.copy()\n",
    "        xtrain, xtest, y_train, y_test = make_train_test(df, configs)       \n",
    "\n",
    "        # pipe.fit(X_train, y_train)\n",
    "        pipe.fit(xtrain, y_train)\n",
    "        \n",
    "        X_train = pipe.transform(xtrain)\n",
    "        X_test = pipe.transform(xtest)\n",
    "\n",
    "        X_train[configs['y_col'][0]] = y_train        \n",
    "        X_train['split'] = 'train'\n",
    "        X_test[configs['y_col'][0]] = y_test\n",
    "        X_test['split'] = 'test'        \n",
    "\n",
    "        return pd.concat([X_train, X_test]).reset_index(drop=True)\n",
    "    else:\n",
    "        print('no pipe applied')\n",
    "        return df \n",
    "\n",
    "\n",
    "def do_train(X_train, X_test, y_train, y_test, option):\n",
    "    X_train, X_test, y_train, y_test = X_train.copy(), X_test.copy(), y_train.copy(), y_test.copy()\n",
    "    model = model_selection(option)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    metrics(y_test, y_pred, option)\n",
    "\n",
    "\n",
    "def min_max_scale(df):\n",
    "    df = df.copy()\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df)\n",
    "    return scaler.transform(df)\n",
    "\n",
    "\n",
    "def metrics(y_test, pred, option):\n",
    "    y_test = y_test.copy()\n",
    "    pred = pred.copy()\n",
    "    accuracy = round(accuracy_score(y_test, pred), 2)\n",
    "    precision = round(precision_score(y_test, pred), 2)\n",
    "    recall = round(recall_score(y_test, pred), 2)\n",
    "    f1 = round(f1_score(y_test, pred), 2)\n",
    "    print(option, \"f1 점수:\", f1, \"정확도:\", accuracy, \"정밀도:\", precision, \"재현율:\", recall)\n",
    "    print(confusion_matrix(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "282d374e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Digitalship_PC\\pydev\\digitalship\\data/predictive_machine\\predictive_machine.csv\n",
      "There are 1 date_time variables\n",
      "There are 6 discrete variables\n",
      "There are 6 continuous variables\n",
      "There are 1 categorical variables\n",
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# arv 예1: credit argumet_credit.xlsx\n",
    "# arv 예2: metro argumet_metro.xlsx\n",
    "\n",
    "try:\n",
    "    folder_name = 'predictive_machine' #sys.argv[1]\n",
    "    config_file_name = 'argumet_premachine.xlsx' #sys.argv[2]\n",
    "    cur_path = os.getcwd()\n",
    "    parent = os.path.abspath(os.path.join(cur_path, os.pardir))\n",
    "    config_file = os.path.join(parent, os.path.join('config', f'{config_file_name}'))\n",
    "    configs = pd.read_excel(config_file, header=None).set_index(0).T\n",
    "    configs = configs.to_dict('list')\n",
    "    ori_file_name = configs['file_name'][0].split('.')[0]\n",
    "    configs['file_name'][0] = os.path.join(parent, os.path.join(f'data/{folder_name}', configs['file_name'][0]))\n",
    "    print(configs['file_name'][0])\n",
    "    df_initial = read_data(configs)\n",
    "\n",
    "    # 전처리 저장 경로 정의\n",
    "    dest_path = os.path.join(parent, os.path.join('data_preprocessed', f'{folder_name}'))\n",
    "    dest_path = os.path.join(parent, os.path.join(f'{dest_path}/imputed', f'draft_{ori_file_name}.csv'))       \n",
    "\n",
    "    # 오리지널 데이터셋 저장\n",
    "    df_initial.to_csv(dest_path, index=False)        \n",
    "\n",
    "    # 1. Label 칼럼 인코딩   \n",
    "    df, y_null = y_label_enc(df_initial, configs)\n",
    "\n",
    "    # 2. discrete, continuous, categorical 구분작업\n",
    "    df_organized, discrete, continuous, categorical = organize_data(df, configs, y_null)\n",
    "\n",
    "    # null_impute_types 정의\n",
    "    null_impute_types = ['median', 'mean', 'max', 'min']\n",
    "\n",
    "    for null_impute_type in null_impute_types:        \n",
    "        # 3. pipe 작업\n",
    "        pipe = make_imputer_pipe(discrete, continuous, categorical, null_impute_type=null_impute_type)\n",
    "\n",
    "        # 4. imputation with train/test split\n",
    "        df_imputed = do_imputation(df_organized, configs, pipe)\n",
    "\n",
    "        # 5. 전처리 셋 저장    \n",
    "        dest_path = os.path.join(parent, os.path.join('data_preprocessed', f'{folder_name}'))\n",
    "        dest_path = os.path.join(parent, os.path.join(f'{dest_path}/imputed', f'imputed_{ori_file_name}_{null_impute_type}.csv'))\n",
    "        df_imputed.to_csv(dest_path, index=False)\n",
    "\n",
    "        # 6. 스케일링 작업 및 저장\n",
    "        Y_COL = configs['y_col'][0]\n",
    "        # 6.1 X_train 스케일링\n",
    "        con = df_imputed['split']=='train'                        \n",
    "        X_train_scaled = min_max_scale(df_imputed[con].drop(columns=[Y_COL,'split']))\n",
    "        X_train_scaled = pd.DataFrame(X_train_scaled)\n",
    "        X_train_scaled[Y_COL] = df_imputed[con][Y_COL]\n",
    "        X_train_scaled['split'] = df_imputed[con]['split']\n",
    "        X_train_scaled.columns = df_imputed.columns\n",
    "\n",
    "        # 6.2 X_test 스케일링\n",
    "        con = df_imputed['split']=='test'                        \n",
    "        X_test_scaled = min_max_scale(df_imputed[con].drop(columns=[Y_COL,'split']))\n",
    "        X_test_scaled = pd.DataFrame(X_test_scaled)\n",
    "        tmp = df_imputed.copy().reset_index()\n",
    "        X_test_scaled['index'] =  tmp[con]['index'].values\n",
    "        X_test_scaled = X_test_scaled.set_index('index')\n",
    "        X_test_scaled[Y_COL] = df_imputed[con][Y_COL]\n",
    "        X_test_scaled['split'] = df_imputed[con]['split']\n",
    "        X_test_scaled.columns = df_imputed.columns\n",
    "        X_test_scaled.index.name = None\n",
    "        del tmp\n",
    "\n",
    "        # 6.3 data frame merge\n",
    "        df_scaled = pd.concat([X_train_scaled, X_test_scaled])\n",
    "        # 6.4 scaling 저장\n",
    "        dest_path = os.path.join(parent, os.path.join('data_preprocessed', f'{folder_name}'))\n",
    "        dest_path = os.path.join(parent, os.path.join(f'{dest_path}/scaled', f'scaled_{ori_file_name}_{null_impute_type}.csv'))\n",
    "        df_scaled.to_csv(dest_path, index=False)\n",
    "\n",
    "    print('Completed.')\n",
    "\n",
    "except Exception as e:\n",
    "    exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "    print('비정상종료', e)\n",
    "    print(exc_type, exc_tb.tb_lineno)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "477a28e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = configs['remove_col'][0].split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "22f005cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UDI', 'Product ID', 'T']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5782330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "51e253ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[\\'\"UDI\",\"Product ID\"\\'] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_initial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mremove_col\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:5399\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5251\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   5252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5260\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5262\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5263\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5264\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5397\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5398\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5401\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5405\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5406\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5407\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4547\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4549\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6934\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6934\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6935\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6936\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: '[\\'\"UDI\",\"Product ID\"\\'] not found in axis'"
     ]
    }
   ],
   "source": [
    " df_initial.drop(configs['remove_col'][0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "515b6c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Machine failure</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M14860</td>\n",
       "      <td>M</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L47181</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L47182</td>\n",
       "      <td>L</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L47183</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L47184</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>M24855</td>\n",
       "      <td>M</td>\n",
       "      <td>298.8</td>\n",
       "      <td>308.4</td>\n",
       "      <td>1604</td>\n",
       "      <td>29.5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>H39410</td>\n",
       "      <td>H</td>\n",
       "      <td>298.9</td>\n",
       "      <td>308.4</td>\n",
       "      <td>1632</td>\n",
       "      <td>31.8</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>M24857</td>\n",
       "      <td>M</td>\n",
       "      <td>299.0</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1645</td>\n",
       "      <td>33.4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>H39412</td>\n",
       "      <td>H</td>\n",
       "      <td>299.0</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>48.5</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>M24859</td>\n",
       "      <td>M</td>\n",
       "      <td>299.0</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1500</td>\n",
       "      <td>40.2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
       "0        M14860    M                298.1                    308.6   \n",
       "1        L47181    L                298.2                    308.7   \n",
       "2        L47182    L                298.1                    308.5   \n",
       "3        L47183    L                298.2                    308.6   \n",
       "4        L47184    L                298.2                    308.7   \n",
       "...         ...  ...                  ...                      ...   \n",
       "9995     M24855    M                298.8                    308.4   \n",
       "9996     H39410    H                298.9                    308.4   \n",
       "9997     M24857    M                299.0                    308.6   \n",
       "9998     H39412    H                299.0                    308.7   \n",
       "9999     M24859    M                299.0                    308.7   \n",
       "\n",
       "      Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  \\\n",
       "0                       1551         42.8                0                0   \n",
       "1                       1408         46.3                3                0   \n",
       "2                       1498         49.4                5                0   \n",
       "3                       1433         39.5                7                0   \n",
       "4                       1408         40.0                9                0   \n",
       "...                      ...          ...              ...              ...   \n",
       "9995                    1604         29.5               14                0   \n",
       "9996                    1632         31.8               17                0   \n",
       "9997                    1645         33.4               22                0   \n",
       "9998                    1408         48.5               25                0   \n",
       "9999                    1500         40.2               30                0   \n",
       "\n",
       "      TWF  HDF  PWF  OSF  RNF  \n",
       "0       0    0    0    0    0  \n",
       "1       0    0    0    0    0  \n",
       "2       0    0    0    0    0  \n",
       "3       0    0    0    0    0  \n",
       "4       0    0    0    0    0  \n",
       "...   ...  ...  ...  ...  ...  \n",
       "9995    0    0    0    0    0  \n",
       "9996    0    0    0    0    0  \n",
       "9997    0    0    0    0    0  \n",
       "9998    0    0    0    0    0  \n",
       "9999    0    0    0    0    0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ab03b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
